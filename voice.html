<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chat de Voz</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background: #0f172a;
            color: white;
        }

        .pulse-ring {
            animation: pulse-ring 2s cubic-bezier(0.215, 0.61, 0.355, 1) infinite;
        }

        @keyframes pulse-ring {
            0% {
                transform: scale(0.9);
                box-shadow: 0 0 0 0 rgba(99, 102, 241, 0.7);
            }

            70% {
                transform: scale(1);
                box-shadow: 0 0 0 20px rgba(99, 102, 241, 0);
            }

            100% {
                transform: scale(0.9);
                box-shadow: 0 0 0 0 rgba(99, 102, 241, 0);
            }
        }

        .speaking {
            animation: bounce 0.5s infinite alternate;
        }

        @keyframes bounce {
            from {
                transform: translateY(0);
            }

            to {
                transform: translateY(-10px);
            }
        }
    </style>
</head>

<body class="h-screen flex flex-col items-center justify-center relative overflow-hidden">

    <div class="absolute top-0 left-0 w-full h-full overflow-hidden z-0">
        <div class="absolute top-[-10%] left-[-10%] w-[40%] h-[40%] bg-indigo-600/20 rounded-full blur-[100px]"></div>
        <div class="absolute bottom-[-10%] right-[-10%] w-[40%] h-[40%] bg-purple-600/20 rounded-full blur-[100px]">
        </div>
    </div>

    <div class="absolute top-6 left-6 z-20 flex items-center gap-4">
        <button onclick="window.location.href='index.html'"
            class="bg-white/10 hover:bg-white/20 p-3 rounded-full backdrop-blur-sm transition-all"><i
                class="fa-solid fa-arrow-left text-white"></i></button>
        <div>
            <h2 id="bot-name" class="text-xl font-bold">Bot</h2>
            <p id="status-text" class="text-sm text-indigo-300">Esperando...</p>
        </div>
    </div>

    <div class="z-10 flex flex-col items-center gap-12 w-full max-w-md px-6">
        <div class="relative">
            <div id="visualizer-ring"
                class="absolute inset-0 rounded-full bg-indigo-500 opacity-20 blur-xl transition-all duration-300">
            </div>
            <div id="bot-avatar"
                class="w-40 h-40 rounded-full bg-slate-800 border-4 border-indigo-500/50 flex items-center justify-center overflow-hidden relative z-10 shadow-2xl">
                <i class="fa-solid fa-robot text-6xl text-slate-600"></i>
            </div>
        </div>
        <div class="w-full text-center space-y-4 min-h-[100px]">
            <p id="user-text" class="text-lg text-gray-300 italic opacity-0 transition-opacity duration-500">"..."</p>
            <p id="bot-text" class="text-xl font-medium text-white transition-all duration-300"></p>
        </div>
        <button id="mic-btn" onclick="toggleListening()"
            class="w-20 h-20 rounded-full bg-indigo-600 hover:bg-indigo-500 flex items-center justify-center shadow-lg shadow-indigo-500/30 transition-all transform hover:scale-105 relative">
            <div id="mic-pulse" class="absolute inset-0 rounded-full bg-indigo-400 opacity-0"></div>
            <i id="mic-icon" class="fa-solid fa-microphone text-3xl text-white"></i>
        </button>
        <p class="text-xs text-gray-500">Toca para hablar</p>
    </div>

    <script type="module">
        import { initializeApp } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-app.js";
        import { getAuth, onAuthStateChanged } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-auth.js";
        import { getFirestore, doc, updateDoc, increment, getDoc, setDoc, arrayUnion } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-firestore.js";

        const firebaseConfig = {
            apiKey: "AIzaSyBs4OlJjJ14WPTQ3u-7VkOjgLKCKQypmTI",
            authDomain: "aiportal-ce688.firebaseapp.com",
            databaseURL: "https://aiportal-ce688-default-rtdb.europe-west1.firebasedatabase.app",
            projectId: "aiportal-ce688",
            storageBucket: "aiportal-ce688.firebasestorage.app",
            messagingSenderId: "217019276864",
            appId: "1:217019276864:web:572d05413bd4ce5fc209a5",
            measurementId: "G-2XKQPLBHN4"
        };

        const app = initializeApp(firebaseConfig);
        const auth = getAuth(app);
        const db = getFirestore(app);
        const appId = "aiportal-ce688";
        const mistralApiKey = "mjVkbhVGVY43LJNMttSLDYOFSYFSkOuv";

        // Instrucciones de sistema optimizadas para voz
        const PRE_SYSTEM_PROMPT = " [SYSTEM: ESTÁS EN MODO DE VOZ. REGLAS ESTRICTAS: 1. NO uses Markdown nunca (nada de asteriscos, negritas o listas). Solo texto plano. 2. Usa frases CORTAS, conversacionales y directas, fáciles de escuchar. 3. MEMORIA: Tienes acceso a recuerdos previos del usuario, ÚSALOS para dar contexto. 4. Si el usuario te cuenta algo nuevo importante (gustos, hechos, etc.), GUÁRDALO escribiendo [MEMO:dato] al final. El usuario NO escuchará lo que pongas entre corchetes, solo tu respuesta hablada.] ";

        let currentBot = null;
        let recognition = null;
        let isListening = false;
        let manualStop = false;
        let chatHistory = [];
        let currentUser = null;
        let currentSpokenText = ""; // Variable para guardar lo que dice el bot y evitar auto-interrupciones
        let audioContext, analyser, microphone;
        let currentVolume = 0;
        let volumeThreshold = 25;

        window.onload = () => {
            const botData = localStorage.getItem('aiportal_current_bot');
            if (!botData) { window.location.href = 'index.html'; return; }
            currentBot = JSON.parse(botData);

            document.getElementById('bot-name').innerText = currentBot.name;
            const avatarContainer = document.getElementById('bot-avatar');
            if (currentBot.avatar && !currentBot.avatar.startsWith('http')) avatarContainer.innerHTML = `<span class="text-6xl">${currentBot.avatar}</span>`;
            else if (currentBot.avatar) avatarContainer.innerHTML = `<img src="${currentBot.avatar}" class="w-full h-full object-cover">`;

            onAuthStateChanged(auth, (user) => { if (user) currentUser = user; else window.location.href = 'index.html'; });


            if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                initVolumeMeter(); // Start volume meter
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                recognition = new SpeechRecognition();
                recognition.lang = 'es-ES';
                recognition.continuous = false;
                recognition.interimResults = true; // Permite detectar el habla antes de terminar la frase

                recognition.onstart = () => {
                    isListening = true;
                    // Si el bot está hablando, no cambiamos la UI a "escuchando" para mantener la animación de hablar
                    if (!window.speechSynthesis.speaking) {
                        updateUIState('listening');
                    }
                };

                recognition.onend = () => {
                    isListening = false;
                    // Si el bot está hablando, reiniciamos inmediatamente para permitir interrupción
                    if (window.speechSynthesis.speaking && !manualStop) {
                        try { recognition.start(); } catch (e) { }
                        return;
                    }

                    const status = document.getElementById('status-text').innerText;

                    if (status === 'Pensando...') return;

                    // Lógica de bucle para mantener la escucha activa
                    if (!manualStop) {
                        setTimeout(() => {
                            if (!isListening) {
                                try { recognition.start(); } catch (e) { updateUIState('idle'); }
                            }
                        }, 100);
                    } else {
                        updateUIState('idle');
                    }
                };

                recognition.onerror = (event) => {
                    console.warn("Speech error", event.error);
                    if (event.error === 'not-allowed' || event.error === 'service-not-allowed') {
                        manualStop = true;
                        updateUIState('idle');
                        alert("Error de micrófono: " + event.error);
                    }
                };

                recognition.onresult = (event) => {
                    let finalTranscript = '';
                    let interimTranscript = '';

                    for (let i = event.resultIndex; i < event.results.length; ++i) {
                        if (event.results[i].isFinal) {
                            finalTranscript += event.results[i][0].transcript;
                        } else {
                            interimTranscript += event.results[i][0].transcript;
                        }
                    }

                    // LÓGICA DE INTERRUPCIÓN (Barge-in):
                    if (window.speechSynthesis.speaking) {
                        const candidate = (interimTranscript + finalTranscript).trim().toLowerCase();

                        // 1. Filtro de Volumen: Si es un susurro o eco lejano, ignorar.
                        // "necesitar mas volumen para que se calle"
                        if (currentVolume < volumeThreshold) {
                            console.log("Ignorando por bajo volumen:", currentVolume);
                            return;
                        }

                        // 2. Filtro de Longitud: Ignorar ruidos cortos. Aumentado para robustez.
                        if (candidate.length < 4) return;

                        // 3. Filtro de Eco Literal: Si coincide mucho con lo que dice el bot.
                        // "hazlo solo si se parece mucho" -> Interpretado como: detectar eco si es muy similar.
                        if (currentSpokenText.toLowerCase().includes(candidate)) {
                            console.log("Ignorando eco detectado:", candidate);
                            return;
                        }

                        // Si pasa volumen y longitud y no es eco --> Interrumpir
                        window.speechSynthesis.cancel();
                        currentSpokenText = "";
                    }

                    if (interimTranscript) {
                        document.getElementById('user-text').innerText = `"${interimTranscript}..."`;
                        document.getElementById('user-text').classList.remove('opacity-0');
                    }

                    if (finalTranscript) {
                        document.getElementById('user-text').innerText = `"${finalTranscript}"`;
                        document.getElementById('user-text').classList.remove('opacity-0');
                        processInput(finalTranscript);
                    }
                };
            } else { alert("Tu navegador no soporta voz."); }
        };

        window.toggleListening = () => {
            if (!recognition) return;
            if (isListening) {
                manualStop = true;
                recognition.stop();
            } else {
                manualStop = false;
                recognition.start();
            }
        };

        function updateUIState(state) {
            const statusText = document.getElementById('status-text');
            const micPulse = document.getElementById('mic-pulse');
            const ring = document.getElementById('visualizer-ring');
            const micIcon = document.getElementById('mic-icon');

            if (state === 'listening') {
                statusText.innerText = "Escuchando...";
                micPulse.classList.add('pulse-ring', 'opacity-100');
                ring.classList.add('scale-110');
                micIcon.className = "fa-solid fa-microphone-lines text-3xl text-white";
            }
            else if (state === 'thinking') {
                statusText.innerText = "Pensando...";
                micPulse.classList.remove('pulse-ring', 'opacity-100');
                ring.classList.add('animate-spin');
                micIcon.className = "fa-solid fa-brain text-3xl text-white animate-pulse";
            }
            else if (state === 'speaking') {
                statusText.innerText = "Hablando...";
                ring.classList.remove('animate-spin');
                ring.classList.add('scale-125', 'opacity-50');
                micIcon.className = "fa-solid fa-volume-high text-3xl text-white";
            }
            else {
                statusText.innerText = "Toca para hablar";
                micPulse.classList.remove('pulse-ring', 'opacity-100');
                ring.classList.remove('scale-110', 'scale-125', 'animate-spin', 'opacity-50');
                micIcon.className = "fa-solid fa-microphone text-3xl text-white";
            }
        }

        // --- MEMORY FUNCTIONS ---
        const getBotData = async (botId) => {
            try {
                if (!currentBot.id && currentBot.name) {
                    return { items: [], lastInteraction: null };
                }
                const docRef = doc(db, 'artifacts', appId, 'users', currentUser.uid, 'memories', currentBot.id || 'unknown');
                const snap = await getDoc(docRef);
                return snap.exists() ? snap.data() : { items: [], lastInteraction: null };
            } catch (e) { console.error(e); return { items: [], lastInteraction: null }; }
        }

        const saveBotMemory = async (botId, text) => {
            if (!currentUser || !botId) return;
            try {
                const now = new Date();
                const timestampStr = `[${now.getDate().toString().padStart(2, '0')}/${(now.getMonth() + 1).toString().padStart(2, '0')}/${now.getFullYear()} ${now.getHours().toString().padStart(2, '0')}:${now.getMinutes().toString().padStart(2, '0')}]`;
                const finalContent = `${timestampStr} ${text}`;

                const docRef = doc(db, 'artifacts', appId, 'users', currentUser.uid, 'memories', botId);
                await setDoc(docRef, { items: arrayUnion(finalContent) }, { merge: true });
                console.log("Memory saved:", finalContent);
            } catch (e) { console.error("Error saving memory", e); }
        }

        const updateLastInteraction = async (botId) => {
            if (!currentUser || !botId) return;
            try {
                const docRef = doc(db, 'artifacts', appId, 'users', currentUser.uid, 'memories', botId);
                await setDoc(docRef, { lastInteraction: Date.now() }, { merge: true });
            } catch (e) { }
        }
        // ----------------------------------------------------

        async function processInput(text) {
            if (!currentUser) return;
            updateUIState('thinking');

            // Contexto Temporal
            const now = new Date();
            const timestamp = `[${now.getHours().toString().padStart(2, '0')}:${now.getMinutes().toString().padStart(2, '0')}]`;
            chatHistory.push({ role: "user", content: `${timestamp} ${text}` });

            // Recuperar Memoria
            const botData = await getBotData(currentBot.id);
            const memories = botData.items || [];
            const lastInteraction = botData.lastInteraction;

            let timeContext = `FECHA Y HORA: ${now.toLocaleString('es-ES')}. `;
            if (lastInteraction) {
                const diffMs = now.getTime() - lastInteraction;
                const diffMins = Math.floor(diffMs / 60000);
                if (diffMins > 60) timeContext += `Hace ${Math.floor(diffMins / 60)} horas que no habláis. `;
                else timeContext += `Hace ${diffMins} minutos que no habláis. `;
            } else {
                timeContext += "Primera vez que habláis por aquí. ";
            }

            let memoryText = "";
            if (memories.length > 0) {
                memoryText = `\n[MEMORIA (Lo que sabes del usuario)]:\n${memories.map(m => `- ${m}`).join('\n')}`;
            }

            const systemContent = PRE_SYSTEM_PROMPT + timeContext + memoryText + " [PERSONALIDAD]: " + currentBot.systemPrompt;

            const delay = ms => new Promise(res => setTimeout(res, ms));
            let aiText = "Error de conexión.";
            let success = false;

            // Bucle de reintentos (Retries)
            for (let i = 0; i < 3; i++) {
                try {
                    const response = await fetch("https://api.mistral.ai/v1/chat/completions", {
                        method: 'POST', headers: { 'Content-Type': 'application/json', 'Authorization': `Bearer ${mistralApiKey}` },
                        body: JSON.stringify({
                            model: "mistral-medium-latest",
                            messages: [{ role: "system", content: systemContent }, ...chatHistory]
                        })
                    });

                    if (response.status === 429) {
                        console.warn("Rate limit, retrying...");
                        await delay(1000 * (i + 1));
                        continue;
                    }

                    if (!response.ok) throw new Error("API Error");

                    const data = await response.json();
                    aiText = data.choices[0].message.content;
                    success = true;
                    break;
                } catch (e) {
                    console.error("Attempt " + (i + 1) + " failed", e);
                    if (i < 2) await delay(1000);
                }
            }

            if (!success) {
                document.getElementById('bot-text').innerText = "Lo siento, no puedo responder ahora.";
                updateUIState('idle');
                return;
            }

            // Procesar Memos en la respuesta
            const memoRegex = /\[MEMO:(.*?)\]/g;
            let match;
            while ((match = memoRegex.exec(aiText)) !== null) {
                await saveBotMemory(currentBot.id, match[1]);
            }

            // Limpiar texto para hablar (quitar memos y timestamps si los hubiera)
            const textToSpeak = aiText.replace(/\[MEMO:.*?\]/g, "").trim();

            chatHistory.push({ role: "assistant", content: aiText });
            document.getElementById('bot-text').innerText = textToSpeak;

            // Actualizar estadísticas y última interacción
            if (currentUser && currentBot.id) {
                const words = textToSpeak.split(/\s+/).length;
                const userStatsRef = doc(db, 'artifacts', appId, 'users', currentUser.uid, 'data', 'stats');
                updateDoc(userStatsRef, { coins: increment(words) }).catch(e => { });
                await updateLastInteraction(currentBot.id);
            }

            speak(textToSpeak);
        }

        // --- MEDIDOR DE VOLUMEN ---
        function initVolumeMeter() {
            try {
                navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    microphone = audioContext.createMediaStreamSource(stream);
                    analyser = audioContext.createAnalyser();
                    analyser.fftSize = 256;
                    microphone.connect(analyser);

                    const bufferLength = analyser.frequencyBinCount;
                    const dataArray = new Uint8Array(bufferLength);

                    function measure() {
                        if (!isListening && !window.speechSynthesis.speaking) {
                            requestAnimationFrame(measure);
                            return;
                        }
                        analyser.getByteFrequencyData(dataArray);
                        let sum = 0;
                        // Calcular promedio simple
                        for (let i = 0; i < bufferLength; i++) {
                            sum += dataArray[i];
                        }
                        currentVolume = sum / bufferLength;
                        requestAnimationFrame(measure);
                    }
                    measure();
                }).catch(e => console.warn("No se pudo iniciar medidor de volumen:", e));
            } catch (e) { console.warn("AudioContext no soportado"); }
        }

        // --- FUNCIÓN TTS NATIVA DEL NAVEGADOR ---
        function speak(text) {
            updateUIState('speaking');

            if (!('speechSynthesis' in window)) {
                alert("Tu navegador no soporta lectura de voz.");
                updateUIState('idle');
                return;
            }

            // Cancelar cualquier audio anterior
            window.speechSynthesis.cancel();

            currentSpokenText = text; // Guardar texto actual para filtrado de eco

            const utterance = new SpeechSynthesisUtterance(text);
            utterance.lang = 'es-ES'; // Forzar español
            utterance.rate = 1.0;
            utterance.pitch = 1.0;

            // CRÍTICO: Asegurar que la escucha siga activa MIENTRAS el bot habla
            if (recognition && !isListening && !manualStop) {
                try { recognition.start(); } catch (e) { }
            }

            utterance.onend = () => {
                if (manualStop) {
                    updateUIState('idle');
                } else {
                    // Terminó de hablar, volvemos visualmente a "escuchando"
                    updateUIState('listening');

                    // Asegurar que el reconocimiento esté activo si no lo está
                    if (recognition && !isListening) {
                        try { recognition.start(); } catch (e) { }
                    }
                }
            };

            utterance.onerror = (e) => {
                console.error("Error en TTS", e);
                updateUIState('idle');
            };

            window.speechSynthesis.speak(utterance);
        }
    </script>
</body>

</html>